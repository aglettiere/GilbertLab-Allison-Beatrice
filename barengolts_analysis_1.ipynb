{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to:\n",
    "- make it work for argonne files. make sure it detects that there is a barcode file and then incorperate it into split_libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make OTU Table from many file types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this program is, using inputs, to take a variety of file types as an input and to output an OTU table and other analysis based on user preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "from IPython.display import FileLinks, FileLink\n",
    "from functools import partial\n",
    "from os import chdir\n",
    "from shutil import copy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--det_seq_file_type input orig_seqes is file path to the original inputted sequences. calls apropriate function to convert sequences into one FASTA file. outputs path to final FASTA file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def det_seq_file_type(orig_seqs, out_path):\n",
    "    '''This function determines the input type of the sequence file, and converts that file into a single joined read fasta file.'''\n",
    "    \n",
    "    \n",
    "    parts = orig_seqs.split(\"/\")\n",
    "    file_name= parts[-1]\n",
    "    if \".fna\" in file_name or \".fasta\" in file_name or \".fa\" in file_name or \".fsa\" in file_name:\n",
    "        return orig_seqs\n",
    "    if \".zip\" in file_name:\n",
    "        return convert_zip(orig_seqs, out_path)\n",
    "    if \".\" not in file_name:\n",
    "        return convert_folder(orig_seqs, out_path)\n",
    "    if \".sff\" in file_name:\n",
    "        return convert_sff(orig_seqs, out_path)\n",
    "    if \".bam\" in file_name:\n",
    "        return convert_bam(orig_seqs, out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--convert_zip input orig_seqes is file path to the original inputted sequences, where they are in a zip folder. unzips file and calls det_seq_file_type() on unzipped file. outputs path to final FASTA file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_zip(orig_seqs, out_path):\n",
    "    parts = orig_seqs.split(\"/\")\n",
    "    file_name = parts[-1]\n",
    "    file_location = \"/\".join(parts[:-1])\n",
    "    \n",
    "    unzipped_folder_name = file_name[:-4]\n",
    "    \n",
    "    \n",
    "    zfile = zipfile.ZipFile(orig_seqs)\n",
    "    zfile.extractall(out_path + '/' + unzipped_folder_name)\n",
    "            \n",
    "    joined_data = det_seq_file_type(out_path + '/' + unzipped_folder_name, out_path)\n",
    "    \n",
    "    return joined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 cases:\n",
    "1. R1 and R2 in a folder\n",
    "2. R1, R2 and barcode\n",
    "3. subfolders, each containing R1 and R2 (multiple_joined_paired_ends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--convert_folder input orig_seqes is file path to the original inputted sequences, where this is a folder containing R1 and R2 reads, and possibly a file containing barcodes. outputs path to final FASTA file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_folder(orig_seqs, out_path):\n",
    "    files_in_folder = os.listdir(orig_seqs)\n",
    "\n",
    "    r1_files = 0\n",
    "    for f in files_in_folder:\n",
    "        if os.path.isdir(orig_seqs +'/'+ f):\n",
    "            return multiple_joins(orig_seqs, out_path)\n",
    "        elif not os.path.isdir(orig_seqs+ '/' + f):\n",
    "            if 'R1' in f:\n",
    "                r1_files+=1\n",
    "    if r1_files > 1:\n",
    "        return multiple_joins(orig_seqs, out_path)\n",
    "\n",
    "    r_one = \"\"\n",
    "    r_two = \"\"\n",
    "    barcodes = \"\"\n",
    "    joined_data = \"\"\n",
    "\n",
    "    parts = orig_seqs.split(\"/\")\n",
    "    file_location = \"/\".join(parts[:-1])\n",
    "    file_name = parts[-1]\n",
    "\n",
    "    for f in files_in_folder:\n",
    "        if \"R1\" in f or \"r1\" in f:\n",
    "            r_one = f\n",
    "        elif \"R2\" in f or \"r2\" in f:\n",
    "            r_two = f\n",
    "        elif \"barcodes\" or \"Barcodes\" or 'I1' in f:\n",
    "            barcodes = f\n",
    "            \n",
    "\n",
    "    if barcodes == \"\":\n",
    "        forward = orig_seqs+ '/' + r_one\n",
    "        reverse = orig_seqs+ '/' + r_two\n",
    "\n",
    "        !join_paired_ends.py -f $forward -r $reverse -o $out_path\"/joined_data\"\n",
    "    else:\n",
    "        barc = orig_seqs + '/' + barcodes\n",
    "        forward = orig_seqs+ '/' + r_one\n",
    "        reverse = orig_seqs+ '/' + r_two\n",
    "        \n",
    "        !join_paired_ends.py -f $forward -r $reverse -b $barc -o $out_path'/joined_data'\n",
    "\n",
    "\n",
    "    return out_path + '/' + \"joined_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "case 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--multiple_joins input orig_seqes is file path to the original inputted sequences, where this is a folder containing subfolders, where each subfolder contains two files: R1 and R2 reads of the same sequence. outputs path to final FASTA file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def multiple_joins(orig_seqs, out_path):\n",
    "    #Join the forward and reverse sequences\n",
    "    #Works for subfolders and mutiple files within one folder\n",
    "    !multiple_join_paired_ends.py -i $orig_seqs -o $out_path\"/joined_data\"\n",
    "\n",
    "    return out_path + '/' + \"joined_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converts sff file, outputs path to FASTA file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_sff(orig_seqs, out_path):\n",
    "    parts = orig_seqs.split(\"/\")\n",
    "    file_location = \"/\".join(parts[:-1])\n",
    "    \n",
    "    !process_sff -i $orig_seqs -o $out_path\"/joined_data\"\n",
    "    return out_path+ '/' + \"joined_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEED TO FIGURE OUT --convert_bam input orig_seqes is file path to the original inputted sequences, where this is an bam file. outputs path to final FASTA file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def convert_bam(orig_seqs, out_path):\n",
    "#     bedtools bamtofastq [OPTIONS] -i orig_seqs -fq Fasting_Example.fna\n",
    "#     http://bedtools.readthedocs.io/en/latest/content/tools/bamtofastq.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_pipeline(seqs_final, out_path, username, clustering_method, otufasta97, otutext97,gg_13_5_fasta, gg_13_5_txt, mapping_path):\n",
    "    \n",
    "#     Remove the non-joined sequences. different for whether or not there are multiple libraries \n",
    "\n",
    "    in_joined_data = os.listdir(seqs_final)\n",
    "\n",
    "    n_dirs = 0\n",
    "    for f in in_joined_data:\n",
    "        if os.path.isdir(seqs_final+ '/' + f):\n",
    "            n_dirs+=1\n",
    "            to_delete_un1 = seqs_final + '/' + f +\"/fastqjoin.un1.fastq\"\n",
    "            to_delete_un2 = seqs_final + '/'  + f +\"/fastqjoin.un2.fastq\"\n",
    "            !rm -r $to_delete_un1\n",
    "            !rm -r $to_delete_un2\n",
    "\n",
    "    if n_dirs == 0:\n",
    "        !rm -r $seqs_final\"/fastqjoin.un1.fastq\"\n",
    "        !rm -r $seqs_final\"/fastqjoin.un2.fastq\"\n",
    "\n",
    "    # We are going to concatenate all the sequences into 1 to run \n",
    "    # Note the folder for the next step cannot contain this file.\n",
    "    \n",
    "    in_joined_data_2 = os.listdir(seqs_final)\n",
    "    filenames = []\n",
    "    \n",
    "    for f in in_joined_data_2:\n",
    "        if \"_L001_R1_001\" in f:\n",
    "            filenames.append(seqs_final + '/' + f + '/fastqjoin.join.fastq')\n",
    "            \n",
    "\n",
    "    #Rename files in Python\n",
    "    chdir(seqs_final)\n",
    "    file_names = os.listdir(seqs_final)\n",
    "    for ifile in file_names:\n",
    "        os.rename(ifile, str.replace(ifile, \"_\", \"\"))\n",
    "        \n",
    "\n",
    "\n",
    "    #Split libraries. includes saving the fasta files (see qiime parameters) using qiime. Determines how many files (more than 1 R1 or R2), split vs. multiple split.\n",
    "##should have an option to use a barcodes file (-b option in split_libraries.py)\n",
    "    \n",
    "    in_joined_data = os.listdir(seqs_final) \n",
    "    fastq_joined = in_joined_data[0]\n",
    "    n_dirs = 0\n",
    "    for f in in_joined_data:\n",
    "        if os.path.isdir(seqs_final+ '/' + f):\n",
    "            n_dirs+=1\n",
    "    if n_dirs > 1:\n",
    "##Need to have option to use mapping files\n",
    "        print('hi')\n",
    "        !multiple_split_libraries_fastq.py -i '/Users/user/barengolts_otus_1/joined_data' -o $out_path'/split_data' --demultiplexing_method sampleid_by_file --include_input_dir_path --remove_filepath_in_name -p $out_path'/qiime_parameters.txt'\n",
    "    else:\n",
    "        input_seqs = seqs_final + '/' + fastq_joined\n",
    "        !split_libraries_fastq.py -i $input_seqs -o $out_path'/split_data' -b $out_path'/joined_data/fastqjoin.joinbarcodes.fastq' -m $mapping_path\n",
    "    \n",
    "    \n",
    "    #Fixing the names\n",
    "    chdir(out_path+'/split_data')\n",
    "    #!sed 's/L001R1001//g' seqs.fastq > seqs_fixed.fastq \n",
    "    !sed 's/L001R1001//g' seqs.fna > seqs_fixed.fna\n",
    "\n",
    "##reference database is gg_13_8\n",
    "    !identify_chimeric_seqs.py -i $out_path'/split_data/seqs_fixed.fna' -m usearch61 -o $out_path'/usearch_checked_chimeras/' -r $otufasta97\n",
    "\n",
    "    !filter_fasta.py -f $out_path'/split_data/seqs_fixed.fna' -o $out_path'/seqs_nochimeras_filtered.fna' -s $out_path'/usearch_checked_chimeras/chimeras.txt' -n\n",
    "    \n",
    "    \n",
    "    if clustering_method == \"denovo\" or clustering_method == \"Denovo\":\n",
    "        !pick_otus.py -i $out_path'/seqs_nochimeras_filtered.fna' -o $out_path'/OTUclustering_denovo' -m uclust\n",
    "        otu_clust_path = '/OTUclustering_denovo'\n",
    "        !make_otu_table.py -i $out_path'/OTUclustering_denovo/seqs_nochimeras_filtered_otus.txt' -o $out_path$otu_clust_path'/otu_table_denovo.biom'\n",
    "        !biom convert -i $out_path$otu_clust_path'/otu_table_denovo.biom' -o $out_path'/otu_table_'$clustering_method'.txt' --table-type=\"OTU table\" --to-tsv \n",
    "        !biom convert -i $out_path$otu_clust_path'/otu_table_denovo.biom' -o $out_path'/otu_table_'$clustering_method'.json' --table-type=\"OTU table\" --to-json\n",
    "        !mkdir $out_path'/biom_summarize' \n",
    "        !biom summarize-table -i $out_path$otu_clust_path'/otu_table_denovo.biom' -o $out_path'/biom_summarize/otu_table_'$clustering_method'_sum.txt'\n",
    "        !biom summarize-table -i $out_path$otu_clust_path'/otu_table_denovo.biom' -o $out_path'/biom_summarize/otu_table_'$clustering_method'_sumq.txt'  --qualitative\n",
    "        \n",
    "    elif clustering_method == \"open\" or clustering_method == \"Open\":\n",
    "        !pick_open_reference_otus.py -i $out_path'/seqs_nochimeras_filtered.fna' -o $out_path'/OTUclustering_openreference_usearch' --reference_fp $otufasta97 -f -m usearch61 -p $out_path'/qiime_parameters.txt'\n",
    "        otu_clust_path = '/OTUclustering_openreference_usearch'\n",
    "        \n",
    "    elif clustering_method == \"closed\" or clustering_method == \"Closed\":  \n",
    "        !pick_closed_reference_otus.py -i $out_path'/seqs_nochimeras_filtered.fna' -o $out_path'/OTUclustering_closedreference' --reference_fp $otufasta97 -f -m usearch61 -p $out_path'/qiime_parameters.txt'\n",
    "        otu_clust_path = '/OTUclustering_closedreference'\n",
    "    \n",
    "    if clustering_method != \"denovo\" or clustering_method != \"Denovo\":\n",
    "        !biom convert -i $out_path$otu_clust_path'/otu_table_mc2_w_tax.biom' -o $out_path'/otu_table_'$clustering_method'.txt' --table-type=\"OTU table\" --to-tsv \n",
    "\n",
    "        !biom convert -i $out_path$otu_clust_path'/otu_table_mc2_w_tax.biom' -o $out_path'/otu_table_'$clustering_method'.json' --table-type=\"OTU table\" --to-json\n",
    "\n",
    "        # Summarize tables\n",
    "        !mkdir $out_path'/biom_summarize' \n",
    "        !biom summarize-table -i $out_path$otu_clust_path'/otu_table_mc2_w_tax.biom' -o $out_path'/biom_summarize/otu_table_'$clustering_method'_sum.txt'\n",
    "        !biom summarize-table -i $out_path$otu_clust_path'/otu_table_mc2_w_tax.biom' -o $out_path'/biom_summarize/otu_table_'$clustering_method'_sumq.txt'  --qualitative\n",
    "    \n",
    "    #======================================================================================================================\n",
    "    #PICRUST\n",
    "    #======================================================================================================================\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#What is the name of your user profile on your computer? The outputs from this program will be located in your user folder.\n",
    "username = 'user'\n",
    "\n",
    "##What is the name of the output folder you would like to create?\n",
    "output_folder = \"barengolts_otus_2\"\n",
    "\n",
    "##What is the path to macqiime on your computer, including the 'macqiime' folder.\n",
    "qiime_path = '/macqiime'\n",
    "\n",
    "out_path =  \"/Users\"+ \"/\" + username + \"/\" + output_folder\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "\n",
    "\n",
    "#orig_seqs is the path to the original inputted sequence, including the file name\n",
    "## What is the path to the DNA sequencing file, including the file name? \n",
    "orig_seqs = '/Users/user/Desktop/Miseq158_Barengolts_13228_ReRUN-32930911_2'\n",
    "\n",
    "#What is the path to your mapping file?\n",
    "mapping_path = ''\n",
    "\n",
    "#seqs_final is path to final sequencing file, including the file name\n",
    "seqs_final = det_seq_file_type(orig_seqs, out_path)\n",
    "\n",
    "##What method would you like to use for clustering (denovo, open, closed)?\n",
    "clustering_method = 'open'\n",
    "\n",
    "## What platform type are you using? Illumina or 454?    \n",
    "platform_type = 'Illumina'\n",
    "\n",
    "##What is the path to gg_13_5?\n",
    "gg_13_5_path = '/Users/user/Desktop/Independent_Study/gg_13_5_otus'\n",
    "\n",
    "gg_13_5_fasta = gg_13_5_path + '/rep_set/97_otus.fasta'\n",
    "gg_13_5_txt = gg_13_5_path + '/taxonomy/97_otu_taxonomy.txt'\n",
    "\n",
    "#dont worry about this stuff rn\n",
    "otufasta97 = '/Users/user/Desktop/Independent_Study/gg_13_8_otus/rep_set/97_otus.fasta'\n",
    "\n",
    "otutxt97  = '/Users/user/Desktop/Independent_Study/gg_13_8_otus/taxonomy/97_otu_taxonomy.txt'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Use the below section to if you would like to set custom parameters\n",
    "##If you do not want to set custom parameters, the default QIIME parameters will be used\n",
    "\n",
    "#Split_libraries_fastq parameters\n",
    "max_bad_run_length = 3\n",
    "quality_threshold = 30\n",
    "sequence_max_n = 1\n",
    "store_demultiplexed_fastq = True\n",
    "#Pick_otus parameters \n",
    "similarity = .9\n",
    "# valid usearch_sort_methods include \"abundance\", \"length\", or \"None\"\n",
    "usearch61_sort_method = \"abundance\"\n",
    "sizeorder = True\n",
    "\n",
    "\n",
    "parameter_file = open(out_path + \"/qiime_parameters.txt\", \"w+\")\n",
    "\n",
    "parameter_file.write(\"# Parameters for defining split_libraries and pick_otus \\n\")\n",
    "parameter_file.write((\"split_libraries_fastq:max_bad_run_length \") + str(max_bad_run_length) + \" \\n\")\n",
    "parameter_file.write(('split_libraries_fastq:phred_quality_threshold ') + str(quality_threshold) + \" \\n\")\n",
    "parameter_file.write((\"split_libraries_fastq:sequence_max_n \") + str(sequence_max_n) + \" \\n\")\n",
    "parameter_file.write((\"split_libraries_fastq:store_demultiplexed_fastq\") + str(store_demultiplexed_fastq) + \" \\n\")\n",
    "parameter_file.write((\"pick_otus:similarity \") + str(similarity) + \" \\n\")\n",
    "parameter_file.write((\"pick_otus:usearch61_sort_method \") + usearch61_sort_method + \" \\n\")\n",
    "parameter_file.write((\"pick_otus:sizeorder \") + str(sizeorder))\n",
    "\n",
    "parameter_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "Traceback (most recent call last):\n",
      "  File \"/macqiime/anaconda/bin/multiple_split_libraries_fastq.py\", line 219, in <module>\n",
      "    main()\n",
      "  File \"/macqiime/anaconda/bin/multiple_split_libraries_fastq.py\", line 216, in main\n",
      "    close_logger_on_success=True)\n",
      "  File \"/macqiime/anaconda/lib/python2.7/site-packages/qiime/workflow/util.py\", line 122, in call_commands_serially\n",
      "    raise WorkflowError(msg)\n",
      "qiime.workflow.util.WorkflowError: \n",
      "\n",
      "*** ERROR RAISED DURING STEP: split_libraries_fastq.py\n",
      "Command run was:\n",
      " split_libraries_fastq.py --phred_quality_threshold 30 --max_bad_run_length 3 --sequence_max_n 1 -i /Users/user/barengolts_otus_1/joined_data/Barengolts37-2041S261L001R1001/fastqjoin.join.fastq,/Users/user/barengolts_otus_1/joined_data/Barengolts80-3034S304L001R1001/fastqjoin.join.fastq,/Users/user/barengolts_otus_1/joined_data/Barengolts19-2023S243L001R1001/fastqjoin.join.fastq,/Users/user/barengolts_otus_1/joined_data/Barengolts66-3020S290L001R1001/fastqjoin.join.fastq,/Users/user/barengolts_otus_1/joined_data/Barengolts43-2048S267L001R1001/fastqjoin.join.fastq,/Users/user/barengolts_otus_1/joined_data/Barengolts58-3012S282L001R1001/fastqjoin.join.fastq,/Users/user/barengolts_otus_1/joined_data/Barengolts2-2002S226L001R1001/fastqjoin.join.fastq,/Users/user/barengolts_otus_1/joined_data/Barengolts47-3001S271L001R1001/fastqjoin.join.fastq,/Users/user/barengolts_otus_1/joined_data/Barengolts53-3007S277L001R1001/fastqjoin.join.fastq,/Users/user/barengolts_otus_1/joined_data/Barengolts56-3010S280L001R1001/fastqjoin.join.fastq,/Users/user/barengolts_otus_1/joined_data/Barengolts33-2037S257L001R1001/fastqjoin.join.fastq,/Users/user/barengolts_otus_1/joined_data/Barengolts62-3016S286L001R1001/fastqjoin.join.fastq,/Users/user/barengolts_otus_1/joined_data/Barengolts84-3038S308L001R1001/fastqjoin.join.fastq,/Users/user/barengolts_otus_1/joined_data/Barengolts39-2043S263L001R1001/fastqjoin.join.fastq,/Users/user/barengolts_otus_1/joined_data/Barengolts8-2010S232L001R1001/fastqjoin.join.fastq,/Users/user/barengolts_otus_1/joined_data/Barengolts72-3026S296L001R1001/fastqjoin.join.fastq,/Users/user/barengolts_otus_1/joined_data/Barengolts7-2009S231L001R1001/fastqjoin.join.fastq,/Users/user/barengolts_otus_1/joined_data/Barengolts24-2028S248L001R1001/fastqjoin.join.fastq,/Users/user/barengolts_otus_1/joined_data/Barengolts30-2034S254L001R1001/fastqjoin.join.fastq,/Users/user/barengolts_otus_1/joined_data/Barengolts15-2019S239L001R1001/fastqjoin.join.fastq,/Users/user/barengolts_otus_1/joined_data/Barengolts27-2031S251L001R1001/fastqjoin.join.fastq,/Users/user/barengolts_otus_1/joined_data/Barengolts21-2025S245L001R1001/fastqjoin.join.fastq,/Users/user/barengolts_otus_1/joined_data/Barengolts54-3008S278L001R1001/fastqjoin.join.fastq,/Users/user/barengolts_otus_1/joined_data/Barengolts4-2004S228L001R1001/fastqjoin.join.fastq --sample_ids Barengolts37-2041S261L001R1001,Barengolts80-3034S304L001R1001,Barengolts19-2023S243L001R1001,Barengolts66-3020S290L001R1001,Barengolts43-2048S267L001R1001,Barengolts58-3012S282L001R1001,Barengolts2-2002S226L001R1001,Barengolts47-3001S271L001R1001,Barengolts53-3007S277L001R1001,Barengolts56-3010S280L001R1001,Barengolts33-2037S257L001R1001,Barengolts62-3016S286L001R1001,Barengolts84-3038S308L001R1001,Barengolts39-2043S263L001R1001,Barengolts8-2010S232L001R1001,Barengolts72-3026S296L001R1001,Barengolts7-2009S231L001R1001,Barengolts24-2028S248L001R1001,Barengolts30-2034S254L001R1001,Barengolts15-2019S239L001R1001,Barengolts27-2031S251L001R1001,Barengolts21-2025S245L001R1001,Barengolts54-3008S278L001R1001,Barengolts4-2004S228L001R1001 -o /Users/user/barengolts_otus_2/split_data  --barcode_type 'not-barcoded'\n",
      "Command returned exit status: 1\n",
      "Stdout:\n",
      "\n",
      "Stderr\n",
      "Traceback (most recent call last):\n",
      "  File \"/macqiime/anaconda/bin/split_libraries_fastq.py\", line 365, in <module>\n",
      "    main()\n",
      "  File \"/macqiime/anaconda/bin/split_libraries_fastq.py\", line 344, in main\n",
      "    for fasta_header, sequence, quality, seq_id in seq_generator:\n",
      "  File \"/macqiime/anaconda/lib/python2.7/site-packages/qiime/split_libraries_fastq.py\", line 239, in process_fastq_single_end_read_file_no_barcode\n",
      "    phred_offset=phred_offset):\n",
      "  File \"/macqiime/anaconda/lib/python2.7/site-packages/qiime/split_libraries_fastq.py\", line 317, in process_fastq_single_end_read_file\n",
      "    parse_fastq(fastq_read_f, strict=False, phred_offset=phred_offset)):\n",
      "  File \"/macqiime/anaconda/lib/python2.7/site-packages/skbio/parse/sequences/fastq.py\", line 174, in parse_fastq\n",
      "    seqid)\n",
      "skbio.parse.sequences._exception.FastqParseError: Failed qual conversion for seq id: CTACGGGAGGCAGCAGTAGGGAATATTGCACAATGGAGGGAACTCTGATGCAGCCATGCCGCGTGTGTGAAGAAGGCCTTCGGGTTGTAAAGCACTTTCGGAGGGGAGGAAAAAAATGACGTTACCCTCAGAAGAAGCACCGGCTAACTCCGTGCCAGCAGCCGCGGTAATACGGAGGGTGCAAGCGTTAATCGGAATAACTGGGCGTAAAGGGCATGCAGGCGGTTCATCAAGTAGGATGTGAAATCCCCGGGCTCAACCTGGGAACAGCATACTAAACTGGTGGACTAGAGTATTGCAGGGGGAGACGGAATTCCAGGTGTAGCGGTGGAATGCGTAGATATCTGGAAGAACACCAAAGGCGAAGGCAGATTTCTGGACGATAACTGACACTCAGGGACGAAAGCATGGGGAGCAAACAGGATTAGATACCCGAGTAGTCC. This may be because you passed an incorrect value for phred_offset.\n",
      "\n",
      "\n",
      "sed: seqs.fna: No such file or directory\n",
      "Traceback (most recent call last):\n",
      "  File \"/macqiime/anaconda/bin/identify_chimeric_seqs.py\", line 354, in <module>\n",
      "    main()\n",
      "  File \"/macqiime/anaconda/bin/identify_chimeric_seqs.py\", line 350, in main\n",
      "    threads=threads)\n",
      "  File \"/macqiime/anaconda/lib/python2.7/site-packages/qiime/identify_chimeric_seqs.py\", line 774, in usearch61_chimera_check\n",
      "    log_lines, verbose, threads)\n",
      "  File \"/macqiime/anaconda/lib/python2.7/site-packages/qiime/identify_chimeric_seqs.py\", line 928, in identify_chimeras_usearch61\n",
      "    HALT_EXEC=HALT_EXEC)\n",
      "  File \"/macqiime/anaconda/lib/python2.7/site-packages/bfillings/usearch.py\", line 2345, in usearch61_chimera_check_denovo\n",
      "    app_result = app()\n",
      "  File \"/macqiime/anaconda/lib/python2.7/site-packages/burrito/util.py\", line 285, in __call__\n",
      "    'StdErr:\\n%s\\n' % open(errfile).read())\n",
      "burrito.util.ApplicationError: Unacceptable application exit status: 1\n",
      "Command:\n",
      "cd \"/Users/user/barengolts_otus_2/usearch_checked_chimeras/\"; usearch61 --mindiffs 3 --uchime_denovo \"/Users/user/barengolts_otus_2/usearch_checked_chimeras/seqs_fixed.fna_consensus_fixed.fasta\" --minh 0.28 --xn 8.0 --minseqlength 64 --mindiv 0.8 --abskew 2.0 --uchimeout \"/Users/user/barengolts_otus_2/usearch_checked_chimeras/seqs_fixed.fna_chimeras_denovo.uchime\" --dn 1.4 --log \"/Users/user/barengolts_otus_2/usearch_checked_chimeras/seqs_fixed.fna_chimeras_denovo.log\" > \"/tmp/tmpnPfym3ySZuYqzzOqBau6.txt\" 2> \"/tmp/tmpSK9nSuR1Dwh3rSYO9jks.txt\"\n",
      "StdOut:\n",
      "usearch_i86osx32 v6.1.544, 4.0Gb RAM (8.6Gb total), 4 cores\n",
      "(C) Copyright 2010-12 Robert C. Edgar, all rights reserved.\n",
      "http://drive5.com/usearch\n",
      "\n",
      "License: sbybfhf@gmail.com\n",
      "\n",
      "\n",
      "StdErr:\n",
      "00:00 1.0Mb Reading /Users/user/barengolts_otus_2/usearch_checked_chimeras/seqs_fixed.fna_consensus_fixed.fasta (empty file)\n",
      "\n",
      "\n",
      "usearch61 --mindiffs 3 --uchime_denovo /Users/user/barengolts_otus_2/usearch_checked_chimeras/seqs_fixed.fna_consensus_fixed.fasta --minh 0.28 --xn 8.0 --minseqlength 64 --mindiv 0.8 --abskew 2.0 --uchimeout /Users/user/barengolts_otus_2/usearch_checked_chimeras/seqs_fixed.fna_chimeras_denovo.uchime --dn 1.4 --log /Users/user/barengolts_otus_2/usearch_checked_chimeras/seqs_fixed.fna_chimeras_denovo.log\n",
      "\n",
      "---Fatal error---\n",
      "Input contains amino acid sequences\n",
      "\n",
      "\n",
      "Error in filter_fasta.py: option -s: file does not exist: '/Users/user/barengolts_otus_2/usearch_checked_chimeras/chimeras.txt'\n",
      "\n",
      "If you need help with QIIME, see:\n",
      "http://help.qiime.org\n",
      "Error in pick_open_reference_otus.py: No filepaths match pattern/name '/Users/user/barengolts_otus_2/seqs_nochimeras_filtered.fna'. All patterns must be matched at least once.\n",
      "\n",
      "If you need help with QIIME, see:\n",
      "http://help.qiime.org\n",
      "Usage: biom convert [options] {-i/--input-fp INPUT-FP -o/--output-fp OUTPUT-FP}\n",
      "\n",
      "[] indicates optional input (order unimportant)\n",
      "{} indicates required input (order unimportant)\n",
      "\n",
      "Convert between BIOM and 'classic' (tab-delimited) table formats. Detailed usage examples can be found here: http://biom-format.org/documentation/biom_conversion.html\n",
      "\n",
      "Example usage: \n",
      "Print help message and exit\n",
      " biom convert -h\n",
      "\n",
      "Converting from classic to BIOM format: Convert the classic file table.txt to a HDF5 BIOM format OTU table\n",
      " biom convert -i table.txt -o table.biom --table-type \"OTU table\" --to-hdf5\n",
      "\n",
      "biom convert: error: option -i: file does not exist: '/Users/user/barengolts_otus_2/OTUclustering_openreference_usearch/otu_table_mc2_w_tax.biom'\n",
      "Usage: biom convert [options] {-i/--input-fp INPUT-FP -o/--output-fp OUTPUT-FP}\n",
      "\n",
      "[] indicates optional input (order unimportant)\n",
      "{} indicates required input (order unimportant)\n",
      "\n",
      "Convert between BIOM and 'classic' (tab-delimited) table formats. Detailed usage examples can be found here: http://biom-format.org/documentation/biom_conversion.html\n",
      "\n",
      "Example usage: \n",
      "Print help message and exit\n",
      " biom convert -h\n",
      "\n",
      "Converting from classic to BIOM format: Convert the classic file table.txt to a HDF5 BIOM format OTU table\n",
      " biom convert -i table.txt -o table.biom --table-type \"OTU table\" --to-hdf5\n",
      "\n",
      "biom convert: error: option -i: file does not exist: '/Users/user/barengolts_otus_2/OTUclustering_openreference_usearch/otu_table_mc2_w_tax.biom'\n",
      "Usage: biom summarize-table [options] {-i/--input-fp INPUT-FP}\n",
      "\n",
      "[] indicates optional input (order unimportant)\n",
      "{} indicates required input (order unimportant)\n",
      "\n",
      "Provides details on the observation counts per sample, including summary statistics, as well as metadata categories associated with samples and observations.\n",
      "\n",
      "Example usage: \n",
      "Print help message and exit\n",
      " biom summarize-table -h\n",
      "\n",
      "Basic script usage: Write a summary of table.biom to table_summary.txt\n",
      " biom summarize-table -i table.biom -o table_summary.txt\n",
      "\n",
      "biom summarize-table: error: option -i: file does not exist: '/Users/user/barengolts_otus_2/OTUclustering_openreference_usearch/otu_table_mc2_w_tax.biom'\n",
      "Usage: biom summarize-table [options] {-i/--input-fp INPUT-FP}\n",
      "\n",
      "[] indicates optional input (order unimportant)\n",
      "{} indicates required input (order unimportant)\n",
      "\n",
      "Provides details on the observation counts per sample, including summary statistics, as well as metadata categories associated with samples and observations.\n",
      "\n",
      "Example usage: \n",
      "Print help message and exit\n",
      " biom summarize-table -h\n",
      "\n",
      "Basic script usage: Write a summary of table.biom to table_summary.txt\n",
      " biom summarize-table -i table.biom -o table_summary.txt\n",
      "\n",
      "biom summarize-table: error: option -i: file does not exist: '/Users/user/barengolts_otus_2/OTUclustering_openreference_usearch/otu_table_mc2_w_tax.biom'\n"
     ]
    }
   ],
   "source": [
    "#run through the pipeline\n",
    "run_pipeline(seqs_final, out_path, username, clustering_method, otufasta97, otutxt97, gg_13_5_fasta, gg_13_5_txt, mapping_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def use_picrust(seqs_final, out_path, username, clustering_method, otufasta97, otutext97,gg_13_5_fasta, gg_13_5_txt):\n",
    "    \n",
    "    #Use the version of GG available from PICRUST gg_13_5\n",
    "    !identify_chimeric_seqs.py -i $out_path'/split_data/seqs_fixed.fna' -m usearch61 -o $out_path'/PICRUST_outputs/usearch_checked_chimeras/' -r $gg_13_5_fasta\n",
    "    \n",
    "    !filter_fasta.py -f $out_path'/split_data/seqs_fixed.fna' -o $out_path'/PICRUST_outputs/seqs_nochimeras_filtered.fna' -s $out_path'/PICRUST_outputs/usearch_checked_chimeras/chimeras.txt' -n\n",
    "    \n",
    "    #create OTU table without chimeras for PICRUST. Must use open reference.\n",
    "    output_otu = '/PICRUST_outputs/OTUclustering_closed'\n",
    "    !pick_otus.py -i $out_path'/PICRUST_outputs/seqs_nochimeras_filtered.fna' -o $out_path$output_otu --refseqs_fp $gg_13_5_fasta -m usearch61_ref  --suppress_new_clusters\n",
    "    \n",
    "    !make_otu_table.py -i $out_path$output_otu'/seqs_nochimeras_filtered_otus.txt' --taxonomy $gg_13_5_txt -o $out_path'/PICRUST_outputs/otu_table.biom'\n",
    "    \n",
    "    !pick_rep_set.py -i $out_path$output_otu'/seqs_nochimeras_filtered_otus.txt' -o $out_path'/PICRUST_outputs/rep_set.fna' -f $out_path\"/PICRUST_outputs/seqs_nochimeras_filtered.fna\"\n",
    "\n",
    "    !assign_taxonomy.py -i $out_path'/PICRUST_outputs/rep_set.fna' -o $out_path'/AssignTaxa' -r $gg_13_5_fasta -t $gg_13_5_txt\n",
    "    \n",
    "    #Align sequences in Qiime (Takes long for large datasets) \n",
    "    !align_seqs.py -i $out_path'/PICRUST_outputs/rep_set.fna' -o $out_path'/PICRUST_outputs/RepSeqAligmenment' -t $'/Users/user/Desktop/Independent_Study/gg_13_5_otus/rep_set_aligned/97_otus.fasta'\n",
    "    \n",
    "    #Filter alignments \n",
    "    !filter_alignment.py -i $out_path'/PICRUST_outputs/RepSeqAligmenment/rep_set_aligned.fasta' -o $out_path'/PICRUST_outputs/FilterAlignment'\n",
    "    \n",
    "    #Make phylogeny -Same results with 85 than 97\n",
    "    !make_phylogeny.py -i $out_path'/PICRUST_outputs/FilterAlignment/rep_set_aligned_pfiltered.fasta' -o $out_path'/PICRUST_outputs/refset.tree'\n",
    "    \n",
    "    !biom convert -i $out_path'/PICRUST_outputs/otu_table.biom' -o $out_path'/PICRUST_outputs/otu_table.txt' --table-type=\"OTU table\" --to-tsv \n",
    "    \n",
    "    !biom convert -i $out_path'/PICRUST_outputs/otu_table.biom' -o $out_path'/PICRUST_outputs/otu_table.json' --table-type=\"OTU table\" --to-json\n",
    "    \n",
    "    # Summarize tables (quantitative and qualitative)\n",
    "    !mkdir $out_path'/PICRUST_outputs/biom_summarize'\n",
    "    !biom summarize-table -i $out_path'/PICRUST_outputs/otu_table.biom' -o $out_path'/PICRUST_outputs/biom_summarize/otu_table_sum.txt'\n",
    "    !biom summarize-table -i $out_path'/PICRUST_outputs/otu_table.biom' -o $out_path'/PICRUST_outputs/biom_summarize/otu_table_sumq.txt'  --qualitative \n",
    "\n",
    "    #Normalize by copy number\n",
    "    # This part is done locally\n",
    "    !normalize_by_copy_number.py -i $out_path'/PICRUST_outputs/otu_table.biom'  -o $out_path'/PICRUST_outputs/norm.biom'\n",
    "    \n",
    "    #Predict metagenomes\n",
    "    !predict_metagenomes.py -i $out_path'/PICRUST_outputs/norm.biom' -o $out_path'/PICRUST_outputs/metagenome_predictions.biom' --with_confidence\n",
    "    \n",
    "    #Categorize by function with level 2 in KEGG (.biom and .txt)\n",
    "    !categorize_by_function.py -i $out_path'/PICRUST_outputs/metagenome_predictions.biom' -c KEGG_Pathways -l 2 -o $out_path'/PICRUST_outputs/predicted_metagenomes.L2.biom'\n",
    "    !categorize_by_function.py -i $out_path'/PICRUST_outputs/metagenome_predictions.biom' -c KEGG_Pathways -l 2 -o $out_path'/PICRUST_outputs/predicted_metagenomes.L2.txt' -f \n",
    "\n",
    "    #Categorize by function with level 3 in KEGG (.biom and .txt)\n",
    "    !categorize_by_function.py -i $out_path'/PICRUST_outputs/metagenome_predictions.biom' -c KEGG_Pathways -l 3 -o $out_path'/PICRUST_outputs/predicted_metagenomes.L3.biom'\n",
    "    !categorize_by_function.py -i $out_path'/PICRUST_outputs/metagenome_predictions.biom' -c KEGG_Pathways -l 3 -o $out_path'/PICRUST_outputs/predicted_metagenomes.L3.txt' -f\n",
    "    \n",
    "    #Prediction of functions by OTUs\n",
    "    !metagenome_contributions.py -i $out_path'/PICRUST_outputs/norm.biom'  -o $out_path'/PICRUST_outputs/ko_metagenome_contributions.tab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(convert_zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- help include:\n",
    "- what the function does  (2-3 lines)\n",
    "- what are the inputs\n",
    "- what are the outputs\n",
    "\n",
    "\n",
    "make it cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from shutil import copy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "copy2('/Users/user/Desktop/argonne_files/Undetermined_S0_L001_I1_001.fastq.gz','/Users/user/Desktop/hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
